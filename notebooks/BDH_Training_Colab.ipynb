{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêâ BDH Interpretability Suite - Training Notebook\n",
    "\n",
    "This notebook trains BDH models on the Europarl parallel corpus for the KRITI 2026 AI Interpretability Challenge.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Download Europarl English-French and English-Portuguese data\n",
    "2. Train a French specialist model\n",
    "3. Train a Portuguese specialist model\n",
    "4. Merge both models into a polyglot\n",
    "5. Generate visualization data for the frontend\n",
    "\n",
    "**Requirements:** Google Colab Pro (for GPU and memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (or upload files)\n",
    "!git clone https://github.com/YOUR_USERNAME/bdh-interpretability.git\n",
    "%cd bdh-interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch numpy datasets tqdm pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Europarl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Europarl for En-Fr and En-Pt\n",
    "!python training/download_europarl.py --languages en-fr en-pt --output data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data files\n",
    "!ls -lh data/en-fr/\n",
    "!ls -lh data/en-pt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train French Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration for French model\n",
    "french_config = \"\"\"\n",
    "train_data: \"data/en-fr/train.bin\"\n",
    "val_data: \"data/en-fr/val.bin\"\n",
    "\n",
    "# Model architecture (must match for merging!)\n",
    "n_layer: 8\n",
    "n_embd: 256\n",
    "n_head: 4\n",
    "mlp_multiplier: 128\n",
    "dropout: 0.1\n",
    "vocab_size: 256\n",
    "\n",
    "# Training\n",
    "batch_size: 32\n",
    "block_size: 512\n",
    "max_iters: 10000\n",
    "learning_rate: 1.0e-3\n",
    "gradient_accumulation_steps: 4\n",
    "\n",
    "# Output\n",
    "output_dir: \"checkpoints\"\n",
    "run_name: \"french_specialist\"\n",
    "\n",
    "device: \"cuda\"\n",
    "dtype: \"bfloat16\"\n",
    "compile_model: true\n",
    "\"\"\"\n",
    "\n",
    "with open('training/configs/french_colab.yaml', 'w') as f:\n",
    "    f.write(french_config)\n",
    "\n",
    "print(\"French config saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train French model\n",
    "!python training/train.py --config training/configs/french_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Portuguese Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration for Portuguese model\n",
    "portuguese_config = \"\"\"\n",
    "train_data: \"data/en-pt/train.bin\"\n",
    "val_data: \"data/en-pt/val.bin\"\n",
    "\n",
    "# Model architecture (MUST match French!)\n",
    "n_layer: 8\n",
    "n_embd: 256\n",
    "n_head: 4\n",
    "mlp_multiplier: 128\n",
    "dropout: 0.1\n",
    "vocab_size: 256\n",
    "\n",
    "# Training\n",
    "batch_size: 32\n",
    "block_size: 512\n",
    "max_iters: 10000\n",
    "learning_rate: 1.0e-3\n",
    "gradient_accumulation_steps: 4\n",
    "\n",
    "# Output\n",
    "output_dir: \"checkpoints\"\n",
    "run_name: \"portuguese_specialist\"\n",
    "\n",
    "device: \"cuda\"\n",
    "dtype: \"bfloat16\"\n",
    "compile_model: true\n",
    "\"\"\"\n",
    "\n",
    "with open('training/configs/portuguese_colab.yaml', 'w') as f:\n",
    "    f.write(portuguese_config)\n",
    "\n",
    "print(\"Portuguese config saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Portuguese model\n",
    "!python training/train.py --config training/configs/portuguese_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two specialists into a polyglot\n",
    "!python analysis/merge.py \\\n",
    "    --model1 checkpoints/french_specialist/checkpoint_best.pt \\\n",
    "    --model2 checkpoints/portuguese_specialist/checkpoint_best.pt \\\n",
    "    --output checkpoints/merged_polyglot.pt \\\n",
    "    --name1 french \\\n",
    "    --name2 portuguese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Monosemanticity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze French model for monosemantic synapses\n",
    "!python analysis/monosemanticity.py \\\n",
    "    --model checkpoints/french_specialist/checkpoint_best.pt \\\n",
    "    --output analysis_results/french/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze merged model\n",
    "!python analysis/monosemanticity.py \\\n",
    "    --model checkpoints/merged_polyglot.pt \\\n",
    "    --output analysis_results/merged/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Playback Data for Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualization data for the French model\n",
    "!python scripts/generate_playback.py \\\n",
    "    --model checkpoints/french_specialist/checkpoint_best.pt \\\n",
    "    --output frontend/public/playback/french/ \\\n",
    "    --include-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate for merged model\n",
    "!python scripts/generate_playback.py \\\n",
    "    --model checkpoints/merged_polyglot.pt \\\n",
    "    --output frontend/public/playback/merged/ \\\n",
    "    --include-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, 'training')\n",
    "from bdh import load_model, ExtractionConfig\n",
    "\n",
    "# Load French model\n",
    "model = load_model('checkpoints/french_specialist/checkpoint_best.pt', 'cuda')\n",
    "print(f\"Loaded model: {model.config.n_layer}L, {model.config.n_embd}D, {model.config.n_head}H\")\n",
    "print(f\"Neurons per head: {model.config.n_neurons}\")\n",
    "print(f\"Total neurons: {model.config.total_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sparsity\n",
    "text = \"The European Parliament adopted the resolution.\"\n",
    "tokens = torch.tensor([list(text.encode('utf-8'))], dtype=torch.long, device='cuda')\n",
    "\n",
    "config = ExtractionConfig(capture_sparse_activations=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with model.extraction_mode(config) as buffer:\n",
    "        logits, _ = model(tokens)\n",
    "        stats = buffer.get_sparsity_stats()\n",
    "\n",
    "print(f\"\\nüìä Sparsity Statistics:\")\n",
    "print(f\"   Overall X sparsity: {stats['overall_x_sparsity']:.1%}\")\n",
    "print(f\"   Overall Y sparsity: {stats['overall_y_sparsity']:.1%}\")\n",
    "print(f\"   Combined sparsity: {stats['overall_sparsity']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation\n",
    "prompt = \"<F:en>The European Union<T:fr>\"\n",
    "prompt_tokens = torch.tensor([list(prompt.encode('utf-8'))], dtype=torch.long, device='cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(prompt_tokens, max_new_tokens=50, top_k=5)\n",
    "\n",
    "generated = bytes(output[0].cpu().tolist()).decode('utf-8', errors='backslashreplace')\n",
    "print(f\"Generated: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip checkpoints and analysis results for download\n",
    "!zip -r bdh_results.zip checkpoints/ analysis_results/ frontend/public/playback/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download (in Colab)\n",
    "from google.colab import files\n",
    "files.download('bdh_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done! üéâ\n",
    "\n",
    "Your trained models and analysis results are ready. Next steps:\n",
    "\n",
    "1. Extract `bdh_results.zip` \n",
    "2. Copy `frontend/public/playback/` files to your local frontend\n",
    "3. Run the frontend: `cd frontend && npm install && npm run dev`\n",
    "4. Explore your trained BDH models!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
